{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying PCA and investigating its effect on the CV score. \n",
    "\n",
    "Started kernel by fabiendaniel: https://www.kaggle.com/fabiendaniel/elo-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tareq Mufaddi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Tareq Mufaddi/Elo/train.csv')\n",
    "df_history = pd.read_csv(\"../Tareq Mufaddi/Elo/historical_transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history.loc[:, 'purchase_date'] = pd.DatetimeIndex(df_history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history['authorized_flag'] = df_history['authorized_flag'].map({'Y':1, 'N':0})\n",
    "df_history['category_1'] = df_history['category_1'].map({'Y':1, 'N':0})\n",
    "df_history['purchase_date'] = pd.to_datetime(df_history['purchase_date'])\n",
    "last_date_hist = datetime.datetime(2018, 2, 28)\n",
    "df_history['time_since_purchase_date'] = ((last_date_hist - df_history['purchase_date']).dt.days)\n",
    "df_history.loc[:, 'purchase_date'] = pd.DatetimeIndex(df_history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "\n",
    "df_history['installments'] = df_history['installments'].replace(999,-1)\n",
    "cols_with_nulls = ['city_id', 'state_id', 'subsector_id', 'installments']\n",
    "for col in cols_with_nulls:\n",
    "    df_history[col] = df_history[col].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_func = {\n",
    "        'authorized_flag': ['mean'],\n",
    "        'city_id': ['nunique'], \n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'installments': ['median', 'max'],\n",
    "        'category_3': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'], \n",
    "        'merchant_id': ['nunique'],\n",
    "        'month_lag': ['min', 'max'],\n",
    "        'purchase_amount': ['sum', 'median', 'max', 'min'],\n",
    "        'purchase_date': ['min', 'max'],\n",
    "        'time_since_purchase_date': ['min', 'max', 'mean'],\n",
    "        'category_2': ['nunique'], \n",
    "        'state_id': ['nunique'], \n",
    "        'subsector_id': ['nunique']\n",
    "        }\n",
    "\n",
    "\n",
    "agg_history = df_history.groupby(['card_id']).agg(agg_func)\n",
    "agg_history.columns = ['hist_' + '_'.join(col).strip() for col in agg_history.columns.values]\n",
    "agg_history.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_all = pd.merge(df_train, agg_history, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../Tareq Mufaddi/Elo//test.csv\")\n",
    "df_test_all = pd.merge(df_test, agg_history, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_label_regr = df_train_all['target']\n",
    "\n",
    "df_train_all = df_train_all.drop(['target',\n",
    "                                    'first_active_month', \n",
    "                                    'card_id'\n",
    "                                    ],\n",
    "                                     axis = 1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_train_all, y_label_regr, test_size=0.7, random_state=42)\n",
    "\n",
    "train_x.reset_index(inplace=True, drop = True)\n",
    "test_x.reset_index(inplace=True, drop = True)\n",
    "train_y.reset_index(inplace=True, drop = True)\n",
    "test_y.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.71439\tvalid_1's rmse: 3.6248\n",
      "[200]\ttraining's rmse: 3.67049\tvalid_1's rmse: 3.59701\n",
      "[300]\ttraining's rmse: 3.64182\tvalid_1's rmse: 3.58443\n",
      "[400]\ttraining's rmse: 3.61954\tvalid_1's rmse: 3.57837\n",
      "[500]\ttraining's rmse: 3.60202\tvalid_1's rmse: 3.57675\n",
      "[600]\ttraining's rmse: 3.58724\tvalid_1's rmse: 3.57594\n",
      "[700]\ttraining's rmse: 3.57252\tvalid_1's rmse: 3.57596\n",
      "[800]\ttraining's rmse: 3.55977\tvalid_1's rmse: 3.57679\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 3.57661\tvalid_1's rmse: 3.57571\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66766\tvalid_1's rmse: 3.80748\n",
      "[200]\ttraining's rmse: 3.62326\tvalid_1's rmse: 3.78337\n",
      "[300]\ttraining's rmse: 3.59436\tvalid_1's rmse: 3.77188\n",
      "[400]\ttraining's rmse: 3.57218\tvalid_1's rmse: 3.76749\n",
      "[500]\ttraining's rmse: 3.55393\tvalid_1's rmse: 3.76566\n",
      "[600]\ttraining's rmse: 3.53874\tvalid_1's rmse: 3.76466\n",
      "[700]\ttraining's rmse: 3.52473\tvalid_1's rmse: 3.76419\n",
      "[800]\ttraining's rmse: 3.51265\tvalid_1's rmse: 3.76406\n",
      "[900]\ttraining's rmse: 3.50085\tvalid_1's rmse: 3.76449\n",
      "Early stopping, best iteration is:\n",
      "[783]\ttraining's rmse: 3.51491\tvalid_1's rmse: 3.76392\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.70863\tvalid_1's rmse: 3.63648\n",
      "[200]\ttraining's rmse: 3.66326\tvalid_1's rmse: 3.61537\n",
      "[300]\ttraining's rmse: 3.63369\tvalid_1's rmse: 3.60745\n",
      "[400]\ttraining's rmse: 3.61069\tvalid_1's rmse: 3.60345\n",
      "[500]\ttraining's rmse: 3.59167\tvalid_1's rmse: 3.60184\n",
      "[600]\ttraining's rmse: 3.57541\tvalid_1's rmse: 3.6015\n",
      "[700]\ttraining's rmse: 3.56128\tvalid_1's rmse: 3.60139\n",
      "[800]\ttraining's rmse: 3.54847\tvalid_1's rmse: 3.60145\n",
      "[900]\ttraining's rmse: 3.53638\tvalid_1's rmse: 3.6018\n",
      "Early stopping, best iteration is:\n",
      "[748]\ttraining's rmse: 3.55528\tvalid_1's rmse: 3.60102\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.69378\tvalid_1's rmse: 3.697\n",
      "[200]\ttraining's rmse: 3.649\tvalid_1's rmse: 3.67772\n",
      "[300]\ttraining's rmse: 3.61914\tvalid_1's rmse: 3.67104\n",
      "[400]\ttraining's rmse: 3.59693\tvalid_1's rmse: 3.66985\n",
      "[500]\ttraining's rmse: 3.57857\tvalid_1's rmse: 3.67019\n",
      "[600]\ttraining's rmse: 3.56331\tvalid_1's rmse: 3.67165\n",
      "Early stopping, best iteration is:\n",
      "[432]\ttraining's rmse: 3.59091\tvalid_1's rmse: 3.66963\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66667\tvalid_1's rmse: 3.80668\n",
      "[200]\ttraining's rmse: 3.6211\tvalid_1's rmse: 3.78617\n",
      "[300]\ttraining's rmse: 3.59129\tvalid_1's rmse: 3.77783\n",
      "[400]\ttraining's rmse: 3.56954\tvalid_1's rmse: 3.77496\n",
      "[500]\ttraining's rmse: 3.55043\tvalid_1's rmse: 3.77372\n",
      "[600]\ttraining's rmse: 3.53516\tvalid_1's rmse: 3.7735\n",
      "[700]\ttraining's rmse: 3.5215\tvalid_1's rmse: 3.77313\n",
      "[800]\ttraining's rmse: 3.50949\tvalid_1's rmse: 3.77422\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 3.52755\tvalid_1's rmse: 3.77309\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.3134,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "features = train_x.columns\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_normal = np.zeros(len(df_train_all))\n",
    "predictions_normal = np.zeros(len(test_x))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x.values, train_y)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_x.iloc[trn_idx][features],\n",
    "                           label=train_y[trn_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train_x.iloc[val_idx][features],\n",
    "                           label=train_y[val_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=200)\n",
    "\n",
    "    oof_normal[val_idx] = clf.predict(train_x.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_normal += clf.predict(test_x[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.94079041e+07,  3.53346406e+06,  5.75364883e+00, ...,\n",
       "         6.93976390e-02, -4.95092076e-02,  7.91549702e-02],\n",
       "       [-1.49087073e+07,  1.34960314e+07, -4.29062754e+01, ...,\n",
       "        -4.82598962e-02,  4.45909873e-02, -4.99463743e-02],\n",
       "       [ 1.27527676e+07,  1.14614689e+06, -7.53711112e+01, ...,\n",
       "         1.30902118e-02, -4.98023302e-02,  9.96072240e-02],\n",
       "       ...,\n",
       "       [-1.25273645e+07,  2.83561452e+06, -3.13058347e+01, ...,\n",
       "         6.91810644e-02, -1.90406090e-02,  8.50344585e-02],\n",
       "       [-9.34452857e+06, -7.01095651e+06, -1.92966316e+02, ...,\n",
       "        -3.08044730e-02, -9.48346930e-03,  1.66133066e-02],\n",
       "       [ 1.54771096e+07,  5.39813040e+05, -2.70075557e+01, ...,\n",
       "         5.04061334e-02,  2.29999281e-03, -2.03523120e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_x)\n",
    "pca.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../Tareq Mufaddi/Elo//test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train_x= pca.transform(train_x)\n",
    "pca_train_x = pca_train_x[:,:3]\n",
    "pca_train_x = pd.DataFrame(pca_train_x, columns=['comp1', 'comp2', 'comp3'])\n",
    "\n",
    "pca_test_x= pca.transform(test_x)\n",
    "pca_test_x = pca_test_x[:,:3]\n",
    "pca_test_x = pd.DataFrame(pca_test_x, columns=['comp1', 'comp2', 'comp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test normal: 3.78331 \n",
      "RMSE test PCA: 3.84118 \n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE test normal: {:<8.5f}\".format(mean_squared_error(predictions_normal, test_y) ** 0.5))\n",
    "print(\"RMSE test PCA: {:<8.5f}\".format(mean_squared_error(predictions_pca, test_y) ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.71241\tvalid_1's rmse: 3.62394\n",
      "[200]\ttraining's rmse: 3.66753\tvalid_1's rmse: 3.5964\n",
      "[300]\ttraining's rmse: 3.63827\tvalid_1's rmse: 3.58314\n",
      "[400]\ttraining's rmse: 3.61477\tvalid_1's rmse: 3.5783\n",
      "[500]\ttraining's rmse: 3.59641\tvalid_1's rmse: 3.57712\n",
      "[600]\ttraining's rmse: 3.5812\tvalid_1's rmse: 3.57641\n",
      "[700]\ttraining's rmse: 3.56633\tvalid_1's rmse: 3.57684\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 3.58207\tvalid_1's rmse: 3.57616\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66543\tvalid_1's rmse: 3.8044\n",
      "[200]\ttraining's rmse: 3.62048\tvalid_1's rmse: 3.77922\n",
      "[300]\ttraining's rmse: 3.59116\tvalid_1's rmse: 3.76829\n",
      "[400]\ttraining's rmse: 3.56913\tvalid_1's rmse: 3.76313\n",
      "[500]\ttraining's rmse: 3.55061\tvalid_1's rmse: 3.76089\n",
      "[600]\ttraining's rmse: 3.53491\tvalid_1's rmse: 3.76041\n",
      "[700]\ttraining's rmse: 3.52104\tvalid_1's rmse: 3.76055\n",
      "[800]\ttraining's rmse: 3.50783\tvalid_1's rmse: 3.76172\n",
      "Early stopping, best iteration is:\n",
      "[647]\ttraining's rmse: 3.52827\tvalid_1's rmse: 3.76016\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.70656\tvalid_1's rmse: 3.63484\n",
      "[200]\ttraining's rmse: 3.66002\tvalid_1's rmse: 3.61255\n",
      "[300]\ttraining's rmse: 3.62975\tvalid_1's rmse: 3.60385\n",
      "[400]\ttraining's rmse: 3.60619\tvalid_1's rmse: 3.59963\n",
      "[500]\ttraining's rmse: 3.5868\tvalid_1's rmse: 3.59772\n",
      "[600]\ttraining's rmse: 3.57087\tvalid_1's rmse: 3.59757\n",
      "[700]\ttraining's rmse: 3.55694\tvalid_1's rmse: 3.59773\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's rmse: 3.57585\tvalid_1's rmse: 3.59722\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.6924\tvalid_1's rmse: 3.69611\n",
      "[200]\ttraining's rmse: 3.64643\tvalid_1's rmse: 3.67607\n",
      "[300]\ttraining's rmse: 3.61576\tvalid_1's rmse: 3.66989\n",
      "[400]\ttraining's rmse: 3.59259\tvalid_1's rmse: 3.6691\n",
      "[500]\ttraining's rmse: 3.57303\tvalid_1's rmse: 3.66942\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's rmse: 3.59879\tvalid_1's rmse: 3.66881\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66483\tvalid_1's rmse: 3.80531\n",
      "[200]\ttraining's rmse: 3.61805\tvalid_1's rmse: 3.78477\n",
      "[300]\ttraining's rmse: 3.58731\tvalid_1's rmse: 3.77689\n",
      "[400]\ttraining's rmse: 3.56389\tvalid_1's rmse: 3.77406\n",
      "[500]\ttraining's rmse: 3.54381\tvalid_1's rmse: 3.77366\n",
      "[600]\ttraining's rmse: 3.52804\tvalid_1's rmse: 3.77375\n",
      "[700]\ttraining's rmse: 3.51415\tvalid_1's rmse: 3.77439\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's rmse: 3.54033\tvalid_1's rmse: 3.77335\n",
      "RMSE test PCA: 3.78386 \n"
     ]
    }
   ],
   "source": [
    "train_x_2 = pd.concat([train_x, pca_train_x], axis = 1)\n",
    "test_x_2 = pd.concat([test_x, pca_test_x], axis = 1)\n",
    "\n",
    "del train_x\n",
    "del test_x\n",
    "del pca_train_x\n",
    "del pca_test_x\n",
    "\n",
    "#Train LightGBM model\n",
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.3134,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "features = train_x_2.columns\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_pca = np.zeros(len(train_x_2))\n",
    "predictions_all = np.zeros(len(test_x_2))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x_2.values, train_y)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_x_2.iloc[trn_idx][features],\n",
    "                           label=train_y[trn_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train_x_2.iloc[val_idx][features],\n",
    "                           label=train_y[val_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=200)\n",
    "\n",
    "    oof_pca[val_idx] = clf.predict(train_x_2.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_all += clf.predict(test_x_2[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"RMSE test PCA: {:<8.5f}\".format(mean_squared_error(predictions_all, test_y) ** 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.73388816e+06, -2.42371268e+06, -1.21410025e+02, ...,\n",
       "        -4.48191542e-02,  1.71906462e-02,  8.69832983e-03],\n",
       "       [-1.00890361e+07, -4.73788019e+06, -1.53266397e+02, ...,\n",
       "         8.95252473e-02, -5.20158917e-02,  1.53639367e-02],\n",
       "       [-9.02651208e+06, -6.83991761e+06,  7.92498502e+00, ...,\n",
       "         4.86408469e-02,  3.28881060e-02,  1.33499943e-03],\n",
       "       ...,\n",
       "       [ 9.07711004e+06,  2.14835763e+05, -5.57310736e+01, ...,\n",
       "        -1.20515054e-02, -1.22536071e-02,  2.14535760e-03],\n",
       "       [-1.06181691e+07,  3.45372450e+06, -1.54452253e+02, ...,\n",
       "         6.76793833e-02,  2.77244920e-02,  5.35228829e-04],\n",
       "       [ 5.17197133e+06, -1.40530722e+06, -7.90317097e+01, ...,\n",
       "        -1.71331636e-01,  1.35018932e-01,  2.79289974e-03]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df_train_all)\n",
    "pca.transform(df_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by the first 3 PCA components: 0.999999999956983\n"
     ]
    }
   ],
   "source": [
    "var_exp_3 = sum(pca.explained_variance_ratio_[:3])\n",
    "print('Variance explained by the first 3 PCA components:', var_exp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_all = df_test_all.drop(['first_active_month','card_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train_x= pca.transform(df_train_all)\n",
    "pca_train_x = pca_train_x[:,:3]\n",
    "pca_train_x = pd.DataFrame(pca_train_x, columns=['comp1', 'comp2', 'comp3'])\n",
    "\n",
    "pca_test_x= pca.transform(df_test_all)\n",
    "pca_test_x = pca_test_x[:,:3]\n",
    "pca_test_x = pd.DataFrame(pca_test_x, columns=['comp1', 'comp2', 'comp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x.reset_index(inplace=True, drop = True)\n",
    "test_x.reset_index(inplace=True, drop = True)\n",
    "train_y.reset_index(inplace=True, drop = True)\n",
    "test_y.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.83255\tvalid_1's rmse: 3.87503\n",
      "[200]\ttraining's rmse: 3.82455\tvalid_1's rmse: 3.86802\n",
      "[300]\ttraining's rmse: 3.8179\tvalid_1's rmse: 3.86236\n",
      "[400]\ttraining's rmse: 3.8122\tvalid_1's rmse: 3.85772\n",
      "[500]\ttraining's rmse: 3.80727\tvalid_1's rmse: 3.85374\n",
      "[600]\ttraining's rmse: 3.80313\tvalid_1's rmse: 3.85047\n",
      "[700]\ttraining's rmse: 3.79962\tvalid_1's rmse: 3.84761\n",
      "[800]\ttraining's rmse: 3.79652\tvalid_1's rmse: 3.84522\n",
      "[900]\ttraining's rmse: 3.79391\tvalid_1's rmse: 3.84335\n",
      "[1000]\ttraining's rmse: 3.79163\tvalid_1's rmse: 3.84176\n",
      "[1100]\ttraining's rmse: 3.78951\tvalid_1's rmse: 3.84051\n",
      "[1200]\ttraining's rmse: 3.78749\tvalid_1's rmse: 3.83947\n",
      "[1300]\ttraining's rmse: 3.78573\tvalid_1's rmse: 3.83858\n",
      "[1400]\ttraining's rmse: 3.78417\tvalid_1's rmse: 3.83781\n",
      "[1500]\ttraining's rmse: 3.78274\tvalid_1's rmse: 3.83716\n",
      "[1600]\ttraining's rmse: 3.78151\tvalid_1's rmse: 3.83656\n",
      "[1700]\ttraining's rmse: 3.78037\tvalid_1's rmse: 3.83602\n",
      "[1800]\ttraining's rmse: 3.77928\tvalid_1's rmse: 3.83555\n",
      "[1900]\ttraining's rmse: 3.77827\tvalid_1's rmse: 3.83518\n",
      "[2000]\ttraining's rmse: 3.77734\tvalid_1's rmse: 3.83485\n",
      "[2100]\ttraining's rmse: 3.77646\tvalid_1's rmse: 3.83454\n",
      "[2200]\ttraining's rmse: 3.77564\tvalid_1's rmse: 3.83438\n",
      "[2300]\ttraining's rmse: 3.77485\tvalid_1's rmse: 3.83407\n",
      "[2400]\ttraining's rmse: 3.77408\tvalid_1's rmse: 3.83387\n",
      "[2500]\ttraining's rmse: 3.77332\tvalid_1's rmse: 3.83386\n",
      "[2600]\ttraining's rmse: 3.77261\tvalid_1's rmse: 3.83384\n",
      "[2700]\ttraining's rmse: 3.77192\tvalid_1's rmse: 3.83381\n",
      "[2800]\ttraining's rmse: 3.77126\tvalid_1's rmse: 3.83379\n",
      "[2900]\ttraining's rmse: 3.77065\tvalid_1's rmse: 3.83373\n",
      "[3000]\ttraining's rmse: 3.77011\tvalid_1's rmse: 3.8337\n",
      "[3100]\ttraining's rmse: 3.76961\tvalid_1's rmse: 3.83361\n",
      "[3200]\ttraining's rmse: 3.76911\tvalid_1's rmse: 3.83353\n",
      "[3300]\ttraining's rmse: 3.76857\tvalid_1's rmse: 3.83342\n",
      "[3400]\ttraining's rmse: 3.768\tvalid_1's rmse: 3.83332\n",
      "[3500]\ttraining's rmse: 3.76742\tvalid_1's rmse: 3.8332\n",
      "[3600]\ttraining's rmse: 3.76692\tvalid_1's rmse: 3.83313\n",
      "[3700]\ttraining's rmse: 3.76647\tvalid_1's rmse: 3.8331\n",
      "[3800]\ttraining's rmse: 3.76601\tvalid_1's rmse: 3.83307\n",
      "[3900]\ttraining's rmse: 3.76555\tvalid_1's rmse: 3.83305\n",
      "[4000]\ttraining's rmse: 3.76504\tvalid_1's rmse: 3.83303\n",
      "[4100]\ttraining's rmse: 3.7645\tvalid_1's rmse: 3.83293\n",
      "[4200]\ttraining's rmse: 3.76394\tvalid_1's rmse: 3.83279\n",
      "[4300]\ttraining's rmse: 3.76338\tvalid_1's rmse: 3.83267\n",
      "[4400]\ttraining's rmse: 3.76286\tvalid_1's rmse: 3.83257\n",
      "[4500]\ttraining's rmse: 3.76241\tvalid_1's rmse: 3.83249\n",
      "[4600]\ttraining's rmse: 3.76197\tvalid_1's rmse: 3.83245\n",
      "[4700]\ttraining's rmse: 3.76158\tvalid_1's rmse: 3.83247\n",
      "[4800]\ttraining's rmse: 3.7612\tvalid_1's rmse: 3.83247\n",
      "Early stopping, best iteration is:\n",
      "[4618]\ttraining's rmse: 3.7619\tvalid_1's rmse: 3.83244\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.85227\tvalid_1's rmse: 3.79673\n",
      "[200]\ttraining's rmse: 3.84447\tvalid_1's rmse: 3.78971\n",
      "[300]\ttraining's rmse: 3.83777\tvalid_1's rmse: 3.78378\n",
      "[400]\ttraining's rmse: 3.83216\tvalid_1's rmse: 3.77895\n",
      "[500]\ttraining's rmse: 3.82743\tvalid_1's rmse: 3.77502\n",
      "[600]\ttraining's rmse: 3.82343\tvalid_1's rmse: 3.77178\n",
      "[700]\ttraining's rmse: 3.82003\tvalid_1's rmse: 3.76913\n",
      "[800]\ttraining's rmse: 3.817\tvalid_1's rmse: 3.76687\n",
      "[900]\ttraining's rmse: 3.81428\tvalid_1's rmse: 3.76509\n",
      "[1000]\ttraining's rmse: 3.81177\tvalid_1's rmse: 3.76364\n",
      "[1100]\ttraining's rmse: 3.80952\tvalid_1's rmse: 3.76236\n",
      "[1200]\ttraining's rmse: 3.80759\tvalid_1's rmse: 3.7614\n",
      "[1300]\ttraining's rmse: 3.80578\tvalid_1's rmse: 3.76053\n",
      "[1400]\ttraining's rmse: 3.80407\tvalid_1's rmse: 3.75978\n",
      "[1500]\ttraining's rmse: 3.80257\tvalid_1's rmse: 3.75913\n",
      "[1600]\ttraining's rmse: 3.80127\tvalid_1's rmse: 3.75871\n",
      "[1700]\ttraining's rmse: 3.80001\tvalid_1's rmse: 3.75831\n",
      "[1800]\ttraining's rmse: 3.79886\tvalid_1's rmse: 3.75794\n",
      "[1900]\ttraining's rmse: 3.79778\tvalid_1's rmse: 3.75764\n",
      "[2000]\ttraining's rmse: 3.7968\tvalid_1's rmse: 3.75744\n",
      "[2100]\ttraining's rmse: 3.79593\tvalid_1's rmse: 3.7573\n",
      "[2200]\ttraining's rmse: 3.79508\tvalid_1's rmse: 3.75721\n",
      "[2300]\ttraining's rmse: 3.79427\tvalid_1's rmse: 3.75714\n",
      "[2400]\ttraining's rmse: 3.79346\tvalid_1's rmse: 3.75698\n",
      "[2500]\ttraining's rmse: 3.79265\tvalid_1's rmse: 3.75683\n",
      "[2600]\ttraining's rmse: 3.79185\tvalid_1's rmse: 3.75669\n",
      "[2700]\ttraining's rmse: 3.79108\tvalid_1's rmse: 3.75661\n",
      "[2800]\ttraining's rmse: 3.79031\tvalid_1's rmse: 3.75665\n",
      "[2900]\ttraining's rmse: 3.78942\tvalid_1's rmse: 3.75656\n",
      "[3000]\ttraining's rmse: 3.78869\tvalid_1's rmse: 3.75655\n",
      "[3100]\ttraining's rmse: 3.78801\tvalid_1's rmse: 3.75651\n",
      "[3200]\ttraining's rmse: 3.78737\tvalid_1's rmse: 3.75642\n",
      "[3300]\ttraining's rmse: 3.78663\tvalid_1's rmse: 3.75635\n",
      "[3400]\ttraining's rmse: 3.78589\tvalid_1's rmse: 3.7563\n",
      "[3500]\ttraining's rmse: 3.78521\tvalid_1's rmse: 3.75629\n",
      "[3600]\ttraining's rmse: 3.78461\tvalid_1's rmse: 3.75622\n",
      "[3700]\ttraining's rmse: 3.78405\tvalid_1's rmse: 3.75618\n",
      "[3800]\ttraining's rmse: 3.78349\tvalid_1's rmse: 3.75612\n",
      "[3900]\ttraining's rmse: 3.78295\tvalid_1's rmse: 3.75606\n",
      "[4000]\ttraining's rmse: 3.78234\tvalid_1's rmse: 3.75602\n",
      "[4100]\ttraining's rmse: 3.78172\tvalid_1's rmse: 3.756\n",
      "[4200]\ttraining's rmse: 3.78112\tvalid_1's rmse: 3.75603\n",
      "Early stopping, best iteration is:\n",
      "[4089]\ttraining's rmse: 3.78178\tvalid_1's rmse: 3.75599\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.85807\tvalid_1's rmse: 3.77199\n",
      "[200]\ttraining's rmse: 3.8498\tvalid_1's rmse: 3.76517\n",
      "[300]\ttraining's rmse: 3.84287\tvalid_1's rmse: 3.75961\n",
      "[400]\ttraining's rmse: 3.83701\tvalid_1's rmse: 3.75502\n",
      "[500]\ttraining's rmse: 3.83204\tvalid_1's rmse: 3.75132\n",
      "[600]\ttraining's rmse: 3.82784\tvalid_1's rmse: 3.7484\n",
      "[700]\ttraining's rmse: 3.82434\tvalid_1's rmse: 3.74593\n",
      "[800]\ttraining's rmse: 3.82121\tvalid_1's rmse: 3.74393\n",
      "[900]\ttraining's rmse: 3.81846\tvalid_1's rmse: 3.74244\n",
      "[1000]\ttraining's rmse: 3.81605\tvalid_1's rmse: 3.7412\n",
      "[1100]\ttraining's rmse: 3.81392\tvalid_1's rmse: 3.74012\n",
      "[1200]\ttraining's rmse: 3.81198\tvalid_1's rmse: 3.73917\n",
      "[1300]\ttraining's rmse: 3.81031\tvalid_1's rmse: 3.73839\n",
      "[1400]\ttraining's rmse: 3.80881\tvalid_1's rmse: 3.73777\n",
      "[1500]\ttraining's rmse: 3.80742\tvalid_1's rmse: 3.73722\n",
      "[1600]\ttraining's rmse: 3.80617\tvalid_1's rmse: 3.73673\n",
      "[1700]\ttraining's rmse: 3.80499\tvalid_1's rmse: 3.73636\n",
      "[1800]\ttraining's rmse: 3.80388\tvalid_1's rmse: 3.73601\n",
      "[1900]\ttraining's rmse: 3.80274\tvalid_1's rmse: 3.73556\n",
      "[2000]\ttraining's rmse: 3.80176\tvalid_1's rmse: 3.7353\n",
      "[2100]\ttraining's rmse: 3.80087\tvalid_1's rmse: 3.73514\n",
      "[2200]\ttraining's rmse: 3.80003\tvalid_1's rmse: 3.7351\n",
      "[2300]\ttraining's rmse: 3.79915\tvalid_1's rmse: 3.73486\n",
      "[2400]\ttraining's rmse: 3.79827\tvalid_1's rmse: 3.73467\n",
      "[2500]\ttraining's rmse: 3.7974\tvalid_1's rmse: 3.7347\n",
      "[2600]\ttraining's rmse: 3.79657\tvalid_1's rmse: 3.73472\n",
      "Early stopping, best iteration is:\n",
      "[2405]\ttraining's rmse: 3.79822\tvalid_1's rmse: 3.73467\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.80625\tvalid_1's rmse: 3.97753\n",
      "[200]\ttraining's rmse: 3.7984\tvalid_1's rmse: 3.97048\n",
      "[300]\ttraining's rmse: 3.79191\tvalid_1's rmse: 3.96475\n",
      "[400]\ttraining's rmse: 3.78637\tvalid_1's rmse: 3.95988\n",
      "[500]\ttraining's rmse: 3.78159\tvalid_1's rmse: 3.95576\n",
      "[600]\ttraining's rmse: 3.77756\tvalid_1's rmse: 3.95237\n",
      "[700]\ttraining's rmse: 3.77409\tvalid_1's rmse: 3.94969\n",
      "[800]\ttraining's rmse: 3.77111\tvalid_1's rmse: 3.94724\n",
      "[900]\ttraining's rmse: 3.76847\tvalid_1's rmse: 3.94522\n",
      "[1000]\ttraining's rmse: 3.7662\tvalid_1's rmse: 3.94362\n",
      "[1100]\ttraining's rmse: 3.76411\tvalid_1's rmse: 3.94211\n",
      "[1200]\ttraining's rmse: 3.76225\tvalid_1's rmse: 3.94069\n",
      "[1300]\ttraining's rmse: 3.76053\tvalid_1's rmse: 3.93954\n",
      "[1400]\ttraining's rmse: 3.75885\tvalid_1's rmse: 3.93847\n",
      "[1500]\ttraining's rmse: 3.75729\tvalid_1's rmse: 3.93752\n",
      "[1600]\ttraining's rmse: 3.75593\tvalid_1's rmse: 3.93667\n",
      "[1700]\ttraining's rmse: 3.75477\tvalid_1's rmse: 3.93594\n",
      "[1800]\ttraining's rmse: 3.75358\tvalid_1's rmse: 3.93547\n",
      "[1900]\ttraining's rmse: 3.75237\tvalid_1's rmse: 3.93507\n",
      "[2000]\ttraining's rmse: 3.75125\tvalid_1's rmse: 3.93478\n",
      "[2100]\ttraining's rmse: 3.75024\tvalid_1's rmse: 3.93457\n",
      "[2200]\ttraining's rmse: 3.74935\tvalid_1's rmse: 3.93429\n",
      "[2300]\ttraining's rmse: 3.7485\tvalid_1's rmse: 3.93414\n",
      "[2400]\ttraining's rmse: 3.74763\tvalid_1's rmse: 3.93411\n",
      "[2500]\ttraining's rmse: 3.74681\tvalid_1's rmse: 3.934\n",
      "[2600]\ttraining's rmse: 3.74599\tvalid_1's rmse: 3.93396\n",
      "[2700]\ttraining's rmse: 3.74522\tvalid_1's rmse: 3.93394\n",
      "[2800]\ttraining's rmse: 3.74441\tvalid_1's rmse: 3.93399\n",
      "Early stopping, best iteration is:\n",
      "[2652]\ttraining's rmse: 3.74559\tvalid_1's rmse: 3.93393\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.85471\tvalid_1's rmse: 3.78525\n",
      "[200]\ttraining's rmse: 3.84642\tvalid_1's rmse: 3.77876\n",
      "[300]\ttraining's rmse: 3.83957\tvalid_1's rmse: 3.77348\n",
      "[400]\ttraining's rmse: 3.83383\tvalid_1's rmse: 3.76916\n",
      "[500]\ttraining's rmse: 3.82899\tvalid_1's rmse: 3.76566\n",
      "[600]\ttraining's rmse: 3.82475\tvalid_1's rmse: 3.76282\n",
      "[700]\ttraining's rmse: 3.82105\tvalid_1's rmse: 3.76047\n",
      "[800]\ttraining's rmse: 3.81776\tvalid_1's rmse: 3.75858\n",
      "[900]\ttraining's rmse: 3.81489\tvalid_1's rmse: 3.75719\n",
      "[1000]\ttraining's rmse: 3.81242\tvalid_1's rmse: 3.75602\n",
      "[1100]\ttraining's rmse: 3.81023\tvalid_1's rmse: 3.75502\n",
      "[1200]\ttraining's rmse: 3.80831\tvalid_1's rmse: 3.75434\n",
      "[1300]\ttraining's rmse: 3.80654\tvalid_1's rmse: 3.75382\n",
      "[1400]\ttraining's rmse: 3.80495\tvalid_1's rmse: 3.75344\n",
      "[1500]\ttraining's rmse: 3.80342\tvalid_1's rmse: 3.75323\n",
      "[1600]\ttraining's rmse: 3.8019\tvalid_1's rmse: 3.75303\n",
      "[1700]\ttraining's rmse: 3.80054\tvalid_1's rmse: 3.75286\n",
      "[1800]\ttraining's rmse: 3.79925\tvalid_1's rmse: 3.75274\n",
      "[1900]\ttraining's rmse: 3.79805\tvalid_1's rmse: 3.7527\n",
      "[2000]\ttraining's rmse: 3.79697\tvalid_1's rmse: 3.75276\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's rmse: 3.79848\tvalid_1's rmse: 3.75267\n"
     ]
    }
   ],
   "source": [
    "#Train LightGBM model on these 3 PCA components only\n",
    "param = {#'num_leaves': 21,\n",
    "         #'min_data_in_leaf': 49,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 8,\n",
    "         'learning_rate': 0.001,\n",
    "         #\"boosting\": \"gbdt\",\n",
    "         #\"feature_fraction\": 0.5,\n",
    "         #\"bagging_freq\": 1,\n",
    "         #\"bagging_fraction\": 0.5 ,\n",
    "         #\"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         #\"lambda_l1\": 0.3134,\n",
    "         \"random_state\": 133,\n",
    "         #\"is_unbalance\": True,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "features = pca_train_x.columns\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_pca = np.zeros(len(pca_train_x))\n",
    "predictions_pca = np.zeros(len(pca_test_x))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(pca_train_x.values, y_label_regr)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(pca_train_x.iloc[trn_idx][features],\n",
    "                           label=y_label_regr[trn_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "    val_data = lgb.Dataset(pca_train_x.iloc[val_idx][features],\n",
    "                           label=y_label_regr[val_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=200)\n",
    "    \n",
    "    oof_pca[val_idx] = clf.predict(pca_train_x.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_pca += clf.predict(pca_test_x[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions_pca\n",
    "sub_df.to_csv(\"submission_PCA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features + PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_2 = pd.concat([df_train_all, pca_train_x], axis = 1)\n",
    "test_x_2 = pd.concat([df_test_all, pca_test_x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.76001\tvalid_1's rmse: 3.8175\n",
      "[200]\ttraining's rmse: 3.7173\tvalid_1's rmse: 3.79009\n",
      "[300]\ttraining's rmse: 3.69135\tvalid_1's rmse: 3.77899\n",
      "[400]\ttraining's rmse: 3.67324\tvalid_1's rmse: 3.77391\n",
      "[500]\ttraining's rmse: 3.65939\tvalid_1's rmse: 3.772\n",
      "[600]\ttraining's rmse: 3.64774\tvalid_1's rmse: 3.77135\n",
      "[700]\ttraining's rmse: 3.63816\tvalid_1's rmse: 3.77108\n",
      "[800]\ttraining's rmse: 3.62946\tvalid_1's rmse: 3.77119\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's rmse: 3.63896\tvalid_1's rmse: 3.77105\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.77843\tvalid_1's rmse: 3.74504\n",
      "[200]\ttraining's rmse: 3.73521\tvalid_1's rmse: 3.72108\n",
      "[300]\ttraining's rmse: 3.70912\tvalid_1's rmse: 3.71138\n",
      "[400]\ttraining's rmse: 3.69107\tvalid_1's rmse: 3.70722\n",
      "[500]\ttraining's rmse: 3.67722\tvalid_1's rmse: 3.70546\n",
      "[600]\ttraining's rmse: 3.66574\tvalid_1's rmse: 3.70473\n",
      "[700]\ttraining's rmse: 3.65613\tvalid_1's rmse: 3.70459\n",
      "[800]\ttraining's rmse: 3.6476\tvalid_1's rmse: 3.70435\n",
      "[900]\ttraining's rmse: 3.64018\tvalid_1's rmse: 3.70463\n",
      "Early stopping, best iteration is:\n",
      "[763]\ttraining's rmse: 3.65059\tvalid_1's rmse: 3.70431\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.78435\tvalid_1's rmse: 3.71823\n",
      "[200]\ttraining's rmse: 3.74124\tvalid_1's rmse: 3.69455\n",
      "[300]\ttraining's rmse: 3.71514\tvalid_1's rmse: 3.68519\n",
      "[400]\ttraining's rmse: 3.69728\tvalid_1's rmse: 3.68172\n",
      "[500]\ttraining's rmse: 3.6831\tvalid_1's rmse: 3.68072\n",
      "[600]\ttraining's rmse: 3.67104\tvalid_1's rmse: 3.68053\n",
      "[700]\ttraining's rmse: 3.66184\tvalid_1's rmse: 3.68065\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's rmse: 3.67257\tvalid_1's rmse: 3.68038\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.73539\tvalid_1's rmse: 3.91638\n",
      "[200]\ttraining's rmse: 3.69294\tvalid_1's rmse: 3.88705\n",
      "[300]\ttraining's rmse: 3.667\tvalid_1's rmse: 3.874\n",
      "[400]\ttraining's rmse: 3.64855\tvalid_1's rmse: 3.86843\n",
      "[500]\ttraining's rmse: 3.63427\tvalid_1's rmse: 3.86625\n",
      "[600]\ttraining's rmse: 3.62261\tvalid_1's rmse: 3.8656\n",
      "[700]\ttraining's rmse: 3.61273\tvalid_1's rmse: 3.86537\n",
      "[800]\ttraining's rmse: 3.60381\tvalid_1's rmse: 3.86551\n",
      "[900]\ttraining's rmse: 3.59567\tvalid_1's rmse: 3.86567\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's rmse: 3.61249\tvalid_1's rmse: 3.86537\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.77952\tvalid_1's rmse: 3.73319\n",
      "[200]\ttraining's rmse: 3.73535\tvalid_1's rmse: 3.7103\n",
      "[300]\ttraining's rmse: 3.70874\tvalid_1's rmse: 3.70177\n",
      "[400]\ttraining's rmse: 3.69059\tvalid_1's rmse: 3.69849\n",
      "[500]\ttraining's rmse: 3.67584\tvalid_1's rmse: 3.69735\n",
      "[600]\ttraining's rmse: 3.66387\tvalid_1's rmse: 3.69685\n",
      "[700]\ttraining's rmse: 3.65413\tvalid_1's rmse: 3.69718\n",
      "[800]\ttraining's rmse: 3.64556\tvalid_1's rmse: 3.69704\n",
      "Early stopping, best iteration is:\n",
      "[610]\ttraining's rmse: 3.66288\tvalid_1's rmse: 3.69683\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.3134,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "features = train_x_2.columns\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof_pca = np.zeros(len(train_x_2))\n",
    "predictions_all = np.zeros(len(test_x_2))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x_2.values, y_label_regr)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_x_2.iloc[trn_idx][features],\n",
    "                           label=y_label_regr[trn_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train_x_2.iloc[val_idx][features],\n",
    "                           label=y_label_regr[val_idx],\n",
    "                           #categorical_feature=cat_feats\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=200)\n",
    "\n",
    "    oof_pca[val_idx] = clf.predict(train_x_2.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_all += clf.predict(test_x_2[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions_all\n",
    "sub_df.to_csv(\"submission_PCA_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
